{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUn des enjeu sur le DeepLearning et en particulier le Hs NN du WV est d etre capable\\nde refaire le meme model heteroskedastic_2017.h5 que celui fourni par Sadowski en feb 2021)\\nJe vais utilier les mêmes libs et le meme training dataset\\nA Grouazel\\nApril 2021\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Un des enjeu sur le DeepLearning et en particulier le Hs NN du WV est d etre capable\n",
    "de refaire le meme model heteroskedastic_2017.h5 que celui fourni par Sadowski en feb 2021)\n",
    "Je vais utilier les mêmes libs et le meme training dataset\n",
    "A Grouazel\n",
    "April 2021\n",
    "based on the ntebook https://github.com/hawaii-ai/SAR-Wave-Height/blob/master/notebooks/train_model_heteroskedastic.ipynb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network to predict significant wave height from SAR spectra.\n",
    "# Train with heteroskedastic regression uncertainty estimates.\n",
    "# Author: Peter Sadowski, Dec 2020\n",
    "import os, sys\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # Needed to avoid cudnn bug.\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#sys.path = ['../'] + sys.path\n",
    "sys.path.append('/home1/datahome/agrouaze/git/sar_hs_nn/')\n",
    "from sarhspredictor.lib.sarhs.generator import SARGenerator\n",
    "from sarhspredictor.lib.sarhs.heteroskedastic import Gaussian_NLL, Gaussian_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Low-level features.\n",
    "    inputs = Input(shape=(72, 60, 2))\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    cnn = Model(inputs, x)\n",
    "\n",
    "    # High-level features.\n",
    "    inp = Input(shape=(32, ))  # 'hsSM', 'hsWW3v2', 'hsALT', 'altID', 'target' -> dropped\n",
    "    x = Dense(units=256, activation='relu')(inp)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    ann = Model(inputs=inp, outputs=x)\n",
    "    \n",
    "    # Combine\n",
    "    combinedInput = concatenate([cnn.output, ann.output])\n",
    "    x = Dense(256, activation=\"relu\")(combinedInput)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\", name='penultimate')(x)  \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2, activation=\"softplus\", name='output')(x)\n",
    "    model = Model(inputs=[cnn.input, ann.input], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          8448        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 72, 60, 2)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          65792       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 70, 58, 64)   1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 29, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 33, 27, 128)  73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          65792       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 13, 128)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 11, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          65792       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 5, 256)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          65792       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 256)          0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          65792       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          65792       global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          65792       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          65792       dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          131328      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "penultimate (Dense)             (None, 256)          65792       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           penultimate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,365,826\n",
      "Trainable params: 1,365,826\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "momo = define_model()\n",
    "print(momo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell added to get equivalent file sar_hs.h5\n",
    " inspired from https://github.com/hawaii-ai/SAR-Wave-Height/blob/master/scripts/create_dataset_from_nc.ipynb\n",
    " pas mal de petite modif sur le nom des variables et avec les variables deja assemblees\n",
    " \n",
    " dataflow:\n",
    " training dataset ALT_...nc -> ALT_...processed.nc -> aggregate.h5 -> split by groups .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:remove /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201607S_processed.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb input files to train for S1A : 42\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201607S_processed.nc 0 / 42\n",
      "Found 11346 events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/numpy/core/fromnumeric.py:748: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  a.partition(kth, axis=axis, kind=kind, order=order)\n",
      "/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/ipykernel_launcher.py:106: UserWarning: WARNING: valid_min not used since it\n",
      "cannot be safely cast to variable data type\n",
      "/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/ipykernel_launcher.py:106: UserWarning: WARNING: valid_max not used since it\n",
      "cannot be safely cast to variable data type\n",
      "INFO:root:remove /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201601S_processed.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201607S_processed.nc: 8.809 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201601S_processed.nc 1 / 42\n",
      "Found 9760 events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/ipykernel_launcher.py:103: UserWarning: WARNING: valid_min not used since it\n",
      "cannot be safely cast to variable data type\n",
      "INFO:root:remove /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201705S_processed.nc\n",
      "/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/ipykernel_launcher.py:103: UserWarning: WARNING: valid_max not used since it\n",
      "cannot be safely cast to variable data type\n",
      "INFO:root:remove /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201602S_processed.nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201601S_processed.nc: 7.418 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201705S_processed.nc 2 / 42\n",
      "Found 139 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201705S_processed.nc: 0.174 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201602S_processed.nc 3 / 42\n",
      "Found 12874 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201602S_processed.nc: 9.655 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201707S_processed.nc 4 / 42\n",
      "Found 18632 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201707S_processed.nc: 14.650 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201506S_processed.nc 5 / 42\n",
      "Found 5565 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201506S_processed.nc: 5.794 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201610S_processed.nc 6 / 42\n",
      "Found 15740 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201610S_processed.nc: 16.730 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201605S_processed.nc 7 / 42\n",
      "Found 12882 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201605S_processed.nc: 13.802 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201706S_processed.nc 8 / 42\n",
      "Found 9288 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201706S_processed.nc: 9.950 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201611S_processed.nc 9 / 42\n",
      "Found 15970 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201611S_processed.nc: 17.044 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201503S_processed.nc 10 / 42\n",
      "Found 757 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201503S_processed.nc: 0.917 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201502S_processed.nc 11 / 42\n",
      "Found 1118 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201502S_processed.nc: 1.251 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201804S_processed.nc 12 / 42\n",
      "Found 13699 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201804S_processed.nc: 14.244 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201608S_processed.nc 13 / 42\n",
      "Found 15228 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201608S_processed.nc: 16.254 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201509S_processed.nc 14 / 42\n",
      "Found 7749 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201509S_processed.nc: 8.289 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201612S_processed.nc 15 / 42\n",
      "Found 18055 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201612S_processed.nc: 19.154 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201807S_processed.nc 16 / 42\n",
      "Found 5588 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201807S_processed.nc: 5.851 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201711S_processed.nc 17 / 42\n",
      "Found 15039 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201711S_processed.nc: 15.834 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201507S_processed.nc 18 / 42\n",
      "Found 5199 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201507S_processed.nc: 5.543 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201508S_processed.nc 19 / 42\n",
      "Found 9611 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201508S_processed.nc: 10.149 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201708S_processed.nc 20 / 42\n",
      "Found 15389 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201708S_processed.nc: 16.517 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201701S_processed.nc 21 / 42\n",
      "Found 15129 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201701S_processed.nc: 16.383 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201505S_processed.nc 22 / 42\n",
      "Found 2419 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201505S_processed.nc: 2.669 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201510S_processed.nc 23 / 42\n",
      "Found 8096 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201510S_processed.nc: 8.694 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201806S_processed.nc 24 / 42\n",
      "Found 6642 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201806S_processed.nc: 7.029 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201710S_processed.nc 25 / 42\n",
      "Found 11680 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201710S_processed.nc: 12.357 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201703S_processed.nc 26 / 42\n",
      "Found 13246 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201703S_processed.nc: 14.171 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201709S_processed.nc 27 / 42\n",
      "Found 13051 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201709S_processed.nc: 13.942 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201801S_processed.nc 28 / 42\n",
      "Found 13245 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201801S_processed.nc: 15.210 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201504S_processed.nc 29 / 42\n",
      "Found 986 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201504S_processed.nc: 1.772 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201512S_processed.nc 30 / 42\n",
      "Found 12287 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201512S_processed.nc: 12.856 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201805S_processed.nc 31 / 42\n",
      "Found 15738 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201805S_processed.nc: 16.450 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201702S_processed.nc 32 / 42\n",
      "Found 13643 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201702S_processed.nc: 14.595 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201501S_processed.nc 33 / 42\n",
      "Found 305 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201501S_processed.nc: 0.439 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201606S_processed.nc 34 / 42\n",
      "Found 9255 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201606S_processed.nc: 9.708 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201604S_processed.nc 35 / 42\n",
      "Found 18439 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201604S_processed.nc: 19.200 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201802S_processed.nc 36 / 42\n",
      "Found 12506 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201802S_processed.nc: 13.363 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201712S_processed.nc 37 / 42\n",
      "Found 11928 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201712S_processed.nc: 12.489 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201603S_processed.nc 38 / 42\n",
      "Found 11326 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201603S_processed.nc: 11.848 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201609S_processed.nc 39 / 42\n",
      "Found 11851 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201609S_processed.nc: 12.528 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201803S_processed.nc 40 / 42\n",
      "Found 20915 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201803S_processed.nc: 21.911 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201511S_processed.nc 41 / 42\n",
      "Found 7743 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201511S_processed.nc: 8.331 seconds\n",
      "nb input files to train for S1B : 23\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201807S_processed.nc 0 / 23\n",
      "Found 6620 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201807S_processed.nc: 6.982 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201708S_processed.nc 1 / 23\n",
      "Found 16292 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201708S_processed.nc: 17.345 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201612S_processed.nc 2 / 23\n",
      "Found 20109 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201612S_processed.nc: 21.402 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201804S_processed.nc 3 / 23\n",
      "Found 15082 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201804S_processed.nc: 16.094 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201609S_processed.nc 4 / 23\n",
      "Found 12244 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201609S_processed.nc: 13.111 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201801S_processed.nc 5 / 23\n",
      "Found 14340 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201801S_processed.nc: 16.283 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201703S_processed.nc 6 / 23\n",
      "Found 6951 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201703S_processed.nc: 7.383 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201606S_processed.nc 7 / 23\n",
      "Found 766 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201606S_processed.nc: 1.020 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201802S_processed.nc 8 / 23\n",
      "Found 13810 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201802S_processed.nc: 14.598 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201803S_processed.nc 9 / 23\n",
      "Found 22791 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201803S_processed.nc: 23.672 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201709S_processed.nc 10 / 23\n",
      "Found 14432 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201709S_processed.nc: 15.158 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201710S_processed.nc 11 / 23\n",
      "Found 11733 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201710S_processed.nc: 12.298 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201712S_processed.nc 12 / 23\n",
      "Found 12467 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201712S_processed.nc: 13.143 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201702S_processed.nc 13 / 23\n",
      "Found 14995 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201702S_processed.nc: 15.913 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201711S_processed.nc 14 / 23\n",
      "Found 15569 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201711S_processed.nc: 16.498 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201806S_processed.nc 15 / 23\n",
      "Found 7215 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201806S_processed.nc: 7.769 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201701S_processed.nc 16 / 23\n",
      "Found 16825 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201701S_processed.nc: 17.871 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201611S_processed.nc 17 / 23\n",
      "Found 17217 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201611S_processed.nc: 18.347 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201805S_processed.nc 18 / 23\n",
      "Found 17008 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201805S_processed.nc: 18.042 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201707S_processed.nc 19 / 23\n",
      "Found 18878 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201707S_processed.nc: 20.122 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201607S_processed.nc 20 / 23\n",
      "Found 9014 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201607S_processed.nc: 9.420 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201608S_processed.nc 21 / 23\n",
      "Found 15245 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201608S_processed.nc: 16.290 seconds\n",
      "file_dest /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201610S_processed.nc 22 / 23\n",
      "Found 16765 events.\n",
      "elapsed time to build /home1/scratch/agrouaze/training_quach_redo_model/exp0/S1B_ALT_coloc201610S_processed.nc: 17.803 seconds\n"
     ]
    }
   ],
   "source": [
    "# Reads NetCDF4 file, preprocesses data, and writes hdf5 file.\n",
    "# This is much simpler than aggregating multiple files, then\n",
    "# performing preprocessing.\n",
    "# Author: Peter Sadowski, Dec 2020\n",
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "import time\n",
    "import traceback\n",
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from sarhspredictor.lib.sarhs import preprocess\n",
    "\n",
    "# Source and destination filenames.\n",
    "#file_src  = \"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/S1B_201905_test01S/S1B_201905_test01S.nc\"  # Example file containing single observation.\n",
    "#file_dest = \"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/S1B_201905_test01S/S1B_201905_test01S_processed.h5\"\n",
    "#file_src = '/home/datawork-cersat-public/cache/project/mpc-sentinel1/analysis/s1_data_analysis/hs_nn/quach2020/validation/input_output/final2/S1B_20190501_ifr_tmp_input_output_quach2020_pythonv2.nc'\n",
    "#file_src = '/home1/datawork/agrouaze/data/sentinel1/cwave/training_dataset_quach2020_python_v2/S1A_ALT_coloc201501S.nc'\n",
    "out_dd = '/home1/scratch/agrouaze/training_quach_redo_model/exp0/'\n",
    "for sat in ['S1A','S1B']:\n",
    "    lst_training_files = glob.glob(os.path.join('/home1/datawork/agrouaze/data/sentinel1/cwave/training_dataset_quach2020_python_v2/',sat+'*.nc'))\n",
    "    if sat=='S1A':\n",
    "        satellite = 1 # 1=S1A, 0=S1B\n",
    "    else:\n",
    "        satellite = 0\n",
    "    print('nb input files to train for %s : %s'%(sat,len(lst_training_files)))\n",
    "    for ffii,file_src in enumerate(lst_training_files):\n",
    "        file_dest = os.path.join(out_dd,os.path.basename(file_src).replace('.nc','_processed.nc'))\n",
    "        print('file_dest',file_dest,ffii,'/',len(lst_training_files))\n",
    "        if os.path.exists(os.path.dirname(file_dest)) is False:\n",
    "            os.makedirs(os.path.dirname(file_dest))\n",
    "            print('outputdir mkdir')\n",
    "        if os.path.exists(file_dest):\n",
    "            logging.info('remove %s',file_dest)\n",
    "            os.remove(file_dest)\n",
    "        # These variables are expected in the source file.\n",
    "        keys = ['timeSAR', 'lonSAR',  'latSAR', 'incidenceAngle', 'cspcRe', 'cspcIm','py_S','sigma0','normalizedVariance'] # Needed for predictions.\n",
    "        t0 = time.time()\n",
    "#         try:\n",
    "#             h5py.File(file_dest, 'r').close() #try to close the file if it is opened before\n",
    "#         except:\n",
    "#             print('traceback',traceback.format_exc())\n",
    "#             pass\n",
    "            \n",
    "        with Dataset(file_src) as fs, h5py.File(file_dest, 'w') as fd:\n",
    "            # Check input file.\n",
    "            src = fs.variables\n",
    "            for k in keys:\n",
    "                if k not in src.keys():\n",
    "                    raise IOError(f'Variable {k} not found in input file.')\n",
    "            num_examples = src[keys[0]].shape[0]\n",
    "            print(f'Found {num_examples} events.')\n",
    "\n",
    "            # Get 22 CWAVE features. Concatenate 20 parameters with sigma0 and normVar.\n",
    "            #src['S'].set_auto_scale(False) # Some of the NetCDF4 files had some weird scaling.\n",
    "            S = np.array(src['py_S'][:]) #* float(src['py_S'].scale_factor))\n",
    "            cwave = np.hstack([S, src['sigma0'][:].reshape(-1,1), src['normalizedVariance'][:].reshape(-1,1)])\n",
    "            #cwave = src['cwave'][:]\n",
    "            cwave = preprocess.conv_cwave(cwave) # Remove extrema, then standardize with hardcoded mean, vars.\n",
    "            fd.create_dataset('cwave', data=cwave)\n",
    "\n",
    "            # Observation meta data.\n",
    "            latSAR, lonSAR = src['latSAR'][:], src['lonSAR'][:]\n",
    "            latSARcossin = preprocess.conv_position(latSAR) # Computes cos and sin used by NN.\n",
    "            lonSARcossin = preprocess.conv_position(lonSAR)\n",
    "            #latlonSARcossin = src['latlonSARcossin'][:]\n",
    "            fd.create_dataset('latlonSAR', data=np.column_stack([latSAR, lonSAR]))\n",
    "            fd.create_dataset('latlonSARcossin', data=np.hstack([latSARcossin, lonSARcossin]))\n",
    "            #fd.create_dataset('latlonSARcossin', data=latlonSARcossin)\n",
    "\n",
    "            timeSAR = src['timeSAR'][:]\n",
    "            todSAR = preprocess.conv_time(timeSAR)\n",
    "            #todSAR = src['todSAR'][:]\n",
    "            fd.create_dataset('timeSAR', data=timeSAR, shape=(timeSAR.shape[0], 1))\n",
    "            fd.create_dataset('todSAR', data=todSAR, shape=(todSAR.shape[0], 1))\n",
    "\n",
    "            incidence = preprocess.conv_incidence(src['incidenceAngle'][:]) # Separates into 2 var.\n",
    "            fd.create_dataset('incidence', data=incidence)\n",
    "\n",
    "            satellite_indicator = np.ones((src['timeSAR'].shape[0], 1), dtype=float) * satellite\n",
    "            fd.create_dataset('satellite', data=satellite_indicator, shape=(satellite_indicator.shape[0], 1))\n",
    "\n",
    "            # Spectral data.\n",
    "            re = preprocess.conv_real(src['cspcRe'][:])\n",
    "            im = preprocess.conv_imaginary(src['cspcIm'][:])\n",
    "            x = np.stack((re, im), axis=3)\n",
    "            fd.create_dataset('spectrum', data=x)\n",
    "\n",
    "            # Altimeter features.\n",
    "            hsALT = src['hsALT'][:]\n",
    "            fd.create_dataset('hsALT', data=hsALT, shape=(hsALT.shape[0], 1))\n",
    "            dx = preprocess.conv_dx(src['dx'][:])\n",
    "            dt = preprocess.conv_dt(src['dt'][:])\n",
    "            fd.create_dataset('dxdt', data=np.column_stack([dx, dt]))\n",
    "            \n",
    "            timeALT = src['timeALT'][:] #added by agrouaze\n",
    "            fd.create_dataset('timeALT',data=timeALT, shape=(todSAR.shape[0], 1))\n",
    "            \n",
    "            lonALT = src['lonALT'][:] #added by agrouaze\n",
    "            fd.create_dataset('lonALT', data=lonALT)\n",
    "            \n",
    "            latALT = src['latALT'][:] #added by agrouaze\n",
    "            fd.create_dataset('latALT', data=latALT)\n",
    "              \n",
    "            fd.create_dataset('hsSM', data=src['hsSM'][:]) #added by agrouaze\n",
    "            fd.create_dataset('nk', data=src['nk'][:]) #added by agrouaze\n",
    "            fd.create_dataset('dx', data=src['dx'][:]) #added by agrouaze\n",
    "            fd.create_dataset('dt', data=src['dt'][:]) #added by agrouaze\n",
    "            fd.create_dataset('sigma0', data=src['sigma0'][:]) #added by agrouaze\n",
    "            fd.create_dataset('normalizedVariance', data=src['normalizedVariance'][:]) #added by agrouaze\n",
    "            fd.create_dataset('incidenceAngle', data=src['incidenceAngle'][:]) #added by agrouaze\n",
    "            fd.create_dataset('lonSAR', data=src['lonSAR'][:]) #added by agrouaze\n",
    "            fd.create_dataset('latSAR', data=src['latSAR'][:]) #added by agrouaze\n",
    "            fd.create_dataset('cspcRe', data=src['cspcRe'][:]) #added by agrouaze\n",
    "            fd.create_dataset('cspcIm', data=src['cspcIm'][:]) #added by agrouaze\n",
    "            fd.create_dataset('py_S', data=S) #added by agrouaze\n",
    "        print('elapsed time to build %s: %1.3f seconds'%(file_dest,time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate the monthly processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65 files.\n",
      "/home1/scratch/agrouaze/training_quach_redo_model/exp0/S1A_ALT_coloc201501S_processed.nc\n",
      "['S1A', 'ALT', 'coloc201501S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/65 [00:00<00:55,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201502S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/65 [00:01<00:56,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201503S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3/65 [00:02<00:52,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201504S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4/65 [00:03<00:57,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201505S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/65 [00:05<01:15,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201506S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6/65 [00:09<01:59,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201507S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7/65 [00:13<02:23,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201508S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8/65 [00:19<03:29,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201509S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9/65 [00:25<03:56,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201510S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 10/65 [00:30<04:14,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201511S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 11/65 [00:35<04:21,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201512S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12/65 [00:44<05:11,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201601S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 13/65 [00:50<05:15,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201602S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 14/65 [00:59<05:52,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201603S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15/65 [01:07<05:59,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201604S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 16/65 [01:19<07:06,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201605S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 17/65 [01:28<06:58,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201606S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 18/65 [01:34<06:19,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201607S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 19/65 [01:43<06:19,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201608S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 20/65 [01:53<06:38,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201609S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 21/65 [02:02<06:21,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201610S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 22/65 [02:12<06:37,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201611S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 23/65 [02:23<06:49,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201612S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 24/65 [02:35<07:07, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201701S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 25/65 [02:46<06:57, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201702S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 26/65 [02:56<06:41, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201703S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 27/65 [03:05<06:20, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201705S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 28/65 [03:06<04:26,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201706S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 29/65 [03:12<04:11,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201707S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 30/65 [03:25<05:04,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201708S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 31/65 [03:35<05:15,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201709S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 32/65 [03:44<05:03,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201710S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 33/65 [03:52<04:42,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201711S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 34/65 [04:04<04:55,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201712S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 35/65 [04:12<04:33,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201801S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 36/65 [04:21<04:22,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201802S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 37/65 [04:29<04:09,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201803S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 38/65 [04:44<04:47, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201804S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 39/65 [04:53<04:25, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201805S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 40/65 [05:04<04:20, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201806S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 41/65 [05:09<03:29,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A', 'ALT', 'coloc201807S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 42/65 [05:13<02:48,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201606S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 43/65 [05:14<01:59,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201607S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 44/65 [05:20<02:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201608S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 45/65 [05:33<02:36,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201609S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 46/65 [05:42<02:35,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201610S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 47/65 [05:53<02:45,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201611S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 48/65 [06:05<02:48,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201612S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 49/65 [06:19<02:56, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201701S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 50/65 [06:30<02:46, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201702S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 51/65 [06:40<02:31, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201703S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 52/65 [06:46<02:00,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201707S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 53/65 [06:59<02:04, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201708S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 54/65 [07:10<01:56, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201709S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 55/65 [07:20<01:43, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201710S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 56/65 [07:29<01:29,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201711S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 57/65 [07:44<01:32, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201712S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 58/65 [07:53<01:14, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201801S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 59/65 [08:03<01:02, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201802S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 60/65 [08:12<00:50, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201803S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 61/65 [08:27<00:46, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201804S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 62/65 [08:38<00:33, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201805S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 63/65 [08:49<00:22, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201806S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 64/65 [08:54<00:09,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B', 'ALT', 'coloc201807S', 'processed', 'nc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [08:59<00:00,  8.30s/it]\n",
      "INFO:root:done\n"
     ]
    }
   ],
   "source": [
    "from sarhspredictor.bin import aggregate_monthly_training_files\n",
    "import glob\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from importlib import reload\n",
    "reload(aggregate_monthly_training_files)\n",
    "files_src = sorted(glob.glob('/home1/scratch/agrouaze/training_quach_redo_model/exp0/*_processed.nc'))\n",
    "print(f'Found {len(files_src)} files.')\n",
    "print(files_src[0])\n",
    "# file_dest =  \"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/alt/aggregated_ALT.h5\"\n",
    "# file_dest =  \"/mnt/tmp/psadow/sar/aggregated_ALT.h5\"\n",
    "# file_dest = \"/mnt/tmp/psadow/sar/aggregated_2019.h5\"\n",
    "# file_dest =  \"/mnt/lts/nfs_fs02/sadow_lab/preserve/stopa/sar_hs/data/alt/aggregated_2019.h5\"\n",
    "file_dest = os.path.join('/home1/scratch/agrouaze/training_quach_redo_model/exp0',\"aggregated.h5\")\n",
    "\n",
    "# keys = ['timeSAR', 'timeALT', 'lonSAR', 'lonALT', 'latSAR', 'latALT', 'hsALT', 'dx', 'dt', 'nk', 'hsSM', 'incidenceAngle', 'sigma0', 'normalizedVariance', 'S']\n",
    "# keys = ['timeSAR', 'lonSAR',  'latSAR', 'incidenceAngle', 'sigma0', 'normalizedVariance', 'S']\n",
    "# keys += ['cspcRe', 'cspcIm']\n",
    "# keys = ['timeSAR', 'lonSAR',  'latSAR', 'incidenceAngle', 'sigma0', 'normalizedVariance', 'py_S', 'cspcRe', 'cspcIm'] #'py_cspcRe', 'py_cspcIm']\n",
    "keys = ['timeSAR','timeALT','lonSAR','lonALT','latSAR','latALT','hsALT','dx','dt','nk','hsSM','incidenceAngle','sigma0',\n",
    "        'normalizedVariance','cspcRe','cspcIm','cwave','todSAR','py_S'] #\n",
    "aggregate_monthly_training_files.aggregate(files_src,file_dest,keys=keys)\n",
    "logging.info('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source  /home1/scratch/agrouaze/training_quach_redo_model/exp0/aggregated.h5 True\n",
      "cspcIm: float32\n",
      "cspcRe: float32\n",
      "cwave: float64\n",
      "dt: float64\n",
      "dx: float64\n",
      "hsALT: float64\n",
      "hsSM: float64\n",
      "incidenceAngle: float64\n",
      "latALT: float32\n",
      "latSAR: float32\n",
      "lonALT: float32\n",
      "lonSAR: float32\n",
      "month: int64\n",
      "nk: float64\n",
      "normalizedVariance: float32\n",
      "py_S: float64\n",
      "satellite: int64\n",
      "sigma0: float32\n",
      "timeALT: float64\n",
      "timeSAR: float64\n",
      "todSAR: float64\n",
      "year: int64\n",
      "Found 304379 events from years:  [2015, 2016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:taille timeSAR (766426, 1) indices : (766426,) elem : 304379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with [2015, 2016]\n",
      "Found 265052 events from years:  [2017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:taille timeSAR (766426, 1) indices : (766426,) elem : 265052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with [2017]\n",
      "Found 185151 events from years:  [2018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:taille timeSAR (766426, 1) indices : (766426,) elem : 185151\n",
      "INFO:root:group_name: 2015_2016 years: [2015, 2016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with [2018]\n",
      "Done\n",
      "k cspcIm\n",
      "k cspcRe\n",
      "k cwave\n",
      "k dt\n",
      "k dx\n",
      "k hsALT\n",
      "k hsSM\n",
      "k incidenceAngle\n",
      "k latALT\n",
      "k latSAR\n",
      "k lonALT\n",
      "k lonSAR\n",
      "k month\n",
      "k nk\n",
      "k normalizedVariance\n",
      "k py_S\n",
      "k satellite\n",
      "k sigma0\n",
      "k timeALT\n",
      "k timeSAR\n",
      "k todSAR\n",
      "k year\n",
      "start creating the final .h5 file\n",
      "indices 2015 (766426,) 61835\n",
      "indices 2016 (766426,) 315921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:assert that no NaN in high level features!! indices before : 304379\n",
      "INFO:root:indices sum after lat : 304362\n",
      "INFO:root:indices sum after lon : 304362\n",
      "INFO:root:indices sum after inc : 304362\n",
      "INFO:root:indices sum after dx : 304362\n",
      "INFO:root:indices sum after dt : 304362\n",
      "INFO:root:indices sum after time : 304362\n",
      "INFO:root:indices sum after tod : 304362\n",
      "INFO:root:indices sum after sat : 304362\n",
      "INFO:root:indices sum after hsalt : 304362\n",
      "INFO:root:cspcIm shape : (766426, 72, 60)\n",
      "INFO:root:indices sum after Im : 304362\n",
      "INFO:root:indices sum after Re : 304362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304362 events from years:  [2015, 2016]\n",
      "timeSAR (766426, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:fs[cspcRe] : (766426, 72, 60)\n",
      "INFO:root:tmpIm : (304362, 72, 60)\n",
      "INFO:root:group_name: 2017 years: [2017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with [2015, 2016]\n",
      "indices 2017 (766426,) 265306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:assert that no NaN in high level features!! indices before : 265052\n",
      "INFO:root:indices sum after lat : 265052\n",
      "INFO:root:indices sum after lon : 265052\n",
      "INFO:root:indices sum after inc : 265052\n",
      "INFO:root:indices sum after dx : 265052\n",
      "INFO:root:indices sum after dt : 265052\n",
      "INFO:root:indices sum after time : 265052\n",
      "INFO:root:indices sum after tod : 265052\n",
      "INFO:root:indices sum after sat : 265052\n",
      "INFO:root:indices sum after hsalt : 265052\n",
      "INFO:root:cspcIm shape : (766426, 72, 60)\n",
      "INFO:root:indices sum after Im : 265052\n",
      "INFO:root:indices sum after Re : 265052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265052 events from years:  [2017]\n",
      "timeSAR (766426, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:fs[cspcRe] : (766426, 72, 60)\n",
      "INFO:root:tmpIm : (265052, 72, 60)\n",
      "INFO:root:group_name: 2018 years: [2018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with [2017]\n",
      "indices 2018 (766426,) 185199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:assert that no NaN in high level features!! indices before : 185151\n",
      "INFO:root:indices sum after lat : 185151\n",
      "INFO:root:indices sum after lon : 185151\n",
      "INFO:root:indices sum after inc : 185151\n",
      "INFO:root:indices sum after dx : 185151\n",
      "INFO:root:indices sum after dt : 185151\n",
      "INFO:root:indices sum after time : 185151\n",
      "INFO:root:indices sum after tod : 185151\n",
      "INFO:root:indices sum after sat : 185151\n",
      "INFO:root:indices sum after hsalt : 185151\n",
      "INFO:root:cspcIm shape : (766426, 72, 60)\n",
      "INFO:root:indices sum after Im : 185151\n",
      "INFO:root:indices sum after Re : 185151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 185151 events from years:  [2018]\n",
      "timeSAR (766426, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:fs[cspcRe] : (766426, 72, 60)\n",
      "INFO:root:tmpIm : (185151, 72, 60)\n",
      "INFO:root:elapsed time 3549.60 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with [2018]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# the training dataset must be separated into sub groups\n",
    "# long long task (about 30min)\n",
    "import logging\n",
    "import time\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "fmt = '%(asctime)s %(levelname)s %(filename)s(%(lineno)d) %(message)s'\n",
    "logging.basicConfig(level=logging.INFO,format=fmt)\n",
    "import sarhspredictor.lib.sarhs.generator\n",
    "reload(sarhspredictor.lib.sarhs.generator)\n",
    "import split_aggregated_into_groups\n",
    "from importlib import reload\n",
    "reload(split_aggregated_into_groups)\n",
    "file_src2 = os.path.join('/home1/scratch/agrouaze/training_quach_redo_model/exp0/',\"aggregated.h5\")\n",
    "print('source ',file_src2,os.path.exists(file_src2))\n",
    "file_dest2 = '/home1/scratch/agrouaze/training_quach_redo_model/exp0/aggregated_grouped_final_correction_year2017.h5'\n",
    "file_dest2 = '/home1/datawork/agrouaze/data/sentinel1/cwave/training_dataset_quach2020_python/final_dataset_prepared_for_sadowski21_experiment/aggregated_grouped_final_correction_year2017.h5'\n",
    "if os.path.exists(file_dest2):\n",
    "    os.remove(file_dest2)\n",
    "t0 = time.time()\n",
    "split_aggregated_into_groups.split_aggregated_ds(file_src2,file_dest2)\n",
    "split_aggregated_into_groups.split_aggregated_ds_v2(file_src2,file_dest2,test2015=False,exp_id=1)\n",
    "logging.info('elapsed time %1.2f secs',time.time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home1/datahome/agrouaze/sources/sentinel1/hs_total/validation_quach2020/heteroskedastic_2017_agrouaze.h5\n",
      "/home1/scratch/agrouaze/training_quach_redo_model/exp0/aggregated_grouped_final_correction_year2017.h5\n",
      "Epoch 1/123\n",
      "1022/4449 [=====>........................] - ETA: 6:41 - loss: 1.7824 - Gaussian_MSE: 1.8048"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  AssertionError: \nTraceback (most recent call last):\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 69, in __getitem__\n    return self._get_batch_contiguous(idx)\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 99, in _get_batch_contiguous\n    assert not np.any(np.isnan(features))\n\nAssertionError\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[gradient_tape/Gaussian_NLL/sub/Shape_1/_10]]\n  (1) Unknown:  AssertionError: \nTraceback (most recent call last):\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 69, in __getitem__\n    return self._get_batch_contiguous(idx)\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 99, in _get_batch_contiguous\n    assert not np.any(np.isnan(features))\n\nAssertionError\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_9223]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-04137238c444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclbks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  AssertionError: \nTraceback (most recent call last):\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 69, in __getitem__\n    return self._get_batch_contiguous(idx)\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 99, in _get_batch_contiguous\n    assert not np.any(np.isnan(features))\n\nAssertionError\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[gradient_tape/Gaussian_NLL/sub/Shape_1/_10]]\n  (1) Unknown:  AssertionError: \nTraceback (most recent call last):\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home1/datawork/agrouaze/conda_envs2/envs/pytorchtest/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 69, in __getitem__\n    return self._get_batch_contiguous(idx)\n\n  File \"/home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/sarhs/generator.py\", line 99, in _get_batch_contiguous\n    assert not np.any(np.isnan(features))\n\nAssertionError\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_9223]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "import sarhspredictor.lib.sarhs.generator\n",
    "reload(sarhspredictor.lib.sarhs.generator)\n",
    "from sarhspredictor.lib.sarhs.generator import SARGenerator\n",
    "from sarhspredictor.config import model_IFR_replication_quach2020_sadowski_release_5feb2021\n",
    "#file_model = '/home1/scratch/agrouaze/heteroskedastic_2017_agrouaze.h5'\n",
    "file_model = model_IFR_replication_quach2020_sadowski_release_5feb2021 #\n",
    "print(file_model)\n",
    "model = define_model()\n",
    "model.compile(loss=Gaussian_NLL, optimizer=Adam(lr=0.0001), metrics=[Gaussian_MSE])\n",
    "\n",
    "# Dataset\n",
    "batch_size = 128\n",
    "epochs = 123\n",
    "#filename = '../../data/alt/sar_hs.h5'\n",
    "#filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "filename = file_dest2\n",
    "print(file_dest2)\n",
    "train = SARGenerator(filename=filename, \n",
    "                     subgroups=['2015_2016', '2017'], \n",
    "                     batch_size=batch_size)\n",
    "valid = SARGenerator(filename=filename, subgroups=['2018'], batch_size=batch_size)\n",
    "# filename = '/mnt/tmp/psadow/sar/sar_hs.h5'\n",
    "# epochs = 25\n",
    "# train = SARGenerator(filename=filename, \n",
    "#                      subgroups=['2015_2016', '2017', '2018'], # Train on all data without early stopping.\n",
    "#                      batch_size=batch_size)\n",
    "\n",
    "# Callbacks\n",
    "# This LR schedule is slower than in the paper.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1) \n",
    "check = ModelCheckpoint(file_model, monitor='val_loss', verbose=0,\n",
    "                        save_best_only=True, save_weights_only=False,\n",
    "                        mode='auto', save_freq='epoch')\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, \n",
    "                     mode='auto', baseline=None, restore_best_weights=False)\n",
    "clbks = [reduce_lr, check, stop]\n",
    "\n",
    "history = model.fit(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid,\n",
    "                    callbacks=clbks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before count correction \n",
    "# 2128/4449 [=============>................] - ETA: 1:38:24 - loss: 1.4402 - Gaussian_MSE: 1.0588"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchtest",
   "language": "python",
   "name": "pytorchtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
