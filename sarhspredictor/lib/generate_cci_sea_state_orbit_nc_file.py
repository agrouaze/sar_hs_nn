# coding: utf-8
"""
March 2021
inspiration: copy paste from generate_cci_sea_state_daily_nc_file.py but moidification SAFE granularity plus DLR format proposition
A Grouazel
tested/validated in env /home1/datawork/agrouaze/conda_envs2/envs/cwave/bin/python
example usage:
export PYTHONPATH=/home1/datahome/agrouaze/git/osm_landmask_distancecoast
export PYTHONPATH=/home1/datahome/agrouaze/git/swiml2sproc/:$PYTHONPATH
export PYTHONPATH=/home1/datahome/agrouaze/git/mpc/data_collect/:$PYTHONPATH
python /home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/generate_cci_sea_state_orbit_nc_file.py --outputdir /tmp/ --redo --cwave-version v3.1 --dev --verbose --safename /home/datawork-cersat-public/project/mpc-sentinel1/data/esa/sentinel-1a/L2/WV/S1A_WV_OCN__2S/2021/001/S1A_WV_OCN__2SSV_20210101T053947_20210101T060035_035940_0435AC_E7DD.SAFE/
"""

import logging
import sys
import xarray
import os
import time
import glob
import netCDF4
import traceback
os.environ["KMP_WARNINGS"] = "FALSE"
import datetime
import collections
import numpy as np
import pdb
from shared_information import PROJECT_DIR_DATARMOR,sats_acro,DIR_HS_EMP_CWAVE_CCI,VERSION_CWAVE_CCI
from produce_list_file_S1 import writeTheFileList
from sarhspredictor.lib.predict_with_quach2020_on_OCN_using_keras import main_level_1
from sarhspredictor.lib.load_quach_2020_keras_model import load_quach2020_model_v2
from coastaux.lib import swiml2sproc_utils_ancillary_landmask
from sarhspredictor.config import land_polygon_path,land_raster_path
from get_path_from_base_SAFE import get_path_from_base_SAFE
from swiml2sproc.utils.ancillary.seaice import get_seaice_concentration
INPUT_TXT_DIR = '/home1/scratch/agrouaze/sentinel1/L2/WV/hs_total_SAR/v1/'
INPUT_TXT_DIR = '/home1/datahome/agrouaze/sentinel1/L2/WV/hs_total_SAR/v1/'
INPUT_TXT_DIR = '/home1/datawork/agrouaze/sentinel1/L2/WV/hs_total_SAR/v1/'
OUTDIR = '/home/cercache/users/agrouaze/temporaire/sentinel1/hs_total_SAR/hs_total_sar_v1_from_L2/'  # first directory for the version with some Hs total SAR bugged due to the mkl lib env issue
OUTDIR = '/home/datawork-cersat-public/project/cci-seastate/sandbox/data/sar/'  # path given by JFP in december2017
OUTDIR = '/home/datawork-cersat-public/project/cci-seastate/sandbox/data/sar/v1.0/'  # contained Hs total only separated by satellite
OUTDIR = '/home/datawork-cersat-public/project/cci-seastate/sandbox/data/sar/v1.1/'  # .nc separated by incidence angle and satellite
OUTDIR = DIR_HS_EMP_CWAVE_CCI

FILE_VERSION = '01'
antarctic_seaice_path="/home/ref-cersat-public/sea-ice/sea-ice-concentration/antarctic/ssmi/CER_PSI_ANT_1D_012_PSI_SS/daily/netcdf/%Y/"
arctic_seaice_path="/home/ref-cersat-public/sea-ice/sea-ice-concentration/arctic/ssmi/CER_PSI_ARC_1D_012_PSI_SS/daily/netcdf/%Y/"


#OUTDIR = '/home1/scratch/agrouaze/'
version_hs_computation = 'v1'  # orignal version reading the txt generated by PRUN
version_hs_computation = 'v1.1'  # new version that compute directly from netCDF with a corrected mkl lib in environement but still using the logpolar->cartesian conversion (January 2019)
version_hs_computation = VERSION_CWAVE_CCI
version_hs_computation = 'v3' # Quach 2020
version_hs_computation = 'v3.1' #modification to have files nc per SAFE
units_dates = 'seconds since 2014-04-06 00:00:00'
# key: values (longname ,type,dimensions,units,descr/longname,vmin,vmax)
variables_infos = {  # ('time','str3')
    #"big_sat_acro" : ("satellite_name",'S3',('time',),'no units','first 3 characters of satellite name',None,None),
    #'big_kcorrup' : ("flag_k_vector_corrupted",'f4',('time',),'no units',
    #                 'flag to indicate if the k vector of original ESA product is corrupted (True) or not (False)',None,
    #                 None),
    'swh' : ("sea_surface_wave_significant_height",'f8',('time',),'m','C band significant wave height',0,30),
    'swh_uncertainty' : (
                        'swh_uncertainty','f8',('time',),'m','standard deviation associated to hs :  level of confidence of the NN model ',0,6),
    'swh_quality':("swh_quality","byte",('time'),"","quality of C band significant wave height measurement","",""),
    'swh_rejection_flags':('swh_rejection_flags','byte',('time'),'','consolidated instrument and ice flags',"",""),
    'incidence_angle' : ("incidence_angle",'f8',('time',),'degree','incidence angle of the WV acquisition',22,38),
    'oswLandFlag':('land_flag','byte',('time'),'','land flag annotated in ESA OCN WV products',0,1),
    'distance_to_coast':('distance_to_coast','f8',('time'),'km','distance to coast for WV image center using hybrid method raster/polygons openstreemap',0,4000),
    'platformName':('platform_name','S3',('time'),'','name of the satellite','',''),
    'lon':('longitude','f8',('time'),'degrees_east','longitude',-180,180),
    'lat':('latitude','f8',('time'),'degrees_north','latitude',-90,90),
    'nrcs' : ("sigma0",'f8',('time',),'dB','sigma0 (Normalized Radar Cross Section)',-30,10),
    'nv' : ("nv",'f8',('time',),'dB','Normalized variance of sigma0',1,3),
    'wind_speed' : ("wind_speed",'f8',('time',),'m.s-1','wind speed coming from ESA OCN WV product (CMOD-based wind inversion without Bayesian scheme)',0,50),
    'heading' : ("satellite_heading",'f8',('time',),'degrees',
                     'satellite heading relative to geographic North in clockwise convention',0,360),
    #'time':('time','f8',('time'),units_dates,'')
}



def read_infos_from_WV_ifremer_archive_v3 ( safename,sato,dev=False ) :
    """
    read OCN L2 WV data and compute on the fly the Hs predicted by NN model
    :args:
        safename (str): basename L2 WV SAFE
        sato (str): S1A
    """
    measu_list = []
    for ss in [sato] :
        fullsafepath = get_path_from_base_SAFE(safename)
        measu_listtmp = glob.glob(os.path.join(fullsafepath,'measurement','*nc'))
        # filter on incidence angle
        #measu_listtmp2 = [ffh for ffh in measu_listtmp if wv in ffh]
        measu_listtmp2 = measu_listtmp # we want wv1 and wv2 together in the same nc files at the end
        measu_list += sorted(measu_listtmp2)
    if dev:
        logging.warning('dev mode reduction of input listing to first 6 ocn')
        measu_list = measu_list[0:6]
    logging.info('Nb ocn files to read: %s',len(measu_list))
    if len(measu_list)>0:
        s1_ocn_wv_ds = main_level_1(measu_list[: :-1],model)
    else:
        s1_ocn_wv_ds = None
    return s1_ocn_wv_ds


def apply_sea_ice_mask(ds,datedt):
    """

    :param ds:
    :param datedt: datetime obj
    :return:
    """
    #TBD
    path_arc = os.path.join(arctic_seaice_path.replace('%Y',datedt.strftime('%Y')),datedt.strftime('%Y%m%d')+'.nc')
    path_ant = os.path.join(antarctic_seaice_path.replace('%Y',datedt.strftime('%Y')),datedt.strftime('%Y%m%d')+'.nc')
    seaice_conc = get_seaice_concentration(ds['oswLon'].values,
                             ds['oswLat'].values,
                             path_arc,
                             path_ant,
                             method='bilinear')
    seaice_max = 10.
    ind_seaice_detected = seaice_conc>seaice_max
    qualityvals = ds['swh_quality'].values
    swh_rejection_flags = ds['swh_rejection_flags'].values
    qualityvals[ind_seaice_detected] = 0  # undefined
    #swh_rejection_flags[ind_seaice_detected] += np.int(2 ** 128)  # not_water
    aa = np.zeros(len(swh_rejection_flags)).astype(int)
    swh_rejection_flags[ind_seaice_detected] += aa[ind_seaice_detected] | (1 << 4)
    ds['swh_quality'] = xarray.DataArray(qualityvals,dims='time')
    ds['swh_rejection_flags'] = xarray.DataArray(swh_rejection_flags,dims='time')
    return ds

def apply_landmask_in_rejection_flag(ds):

    indexon_on_land = (ds['oswLandFlag'].values==1)
    qualityvals = ds['swh_quality'].values
    swh_rejection_flags = ds['swh_rejection_flags'].values
    qualityvals[indexon_on_land] = 0 #undefined
    #swh_rejection_flags[indexon_on_land] += np.int(2 ** 128) #not_water
    aa = np.zeros(len(swh_rejection_flags)).astype(int)
    swh_rejection_flags[indexon_on_land] += aa[indexon_on_land] | (1 << 4)
    ds['swh_quality'] = xarray.DataArray(qualityvals,dims='time')
    ds['swh_rejection_flags'] = xarray.DataArray(swh_rejection_flags,dims='time')
    return ds


def apply_windspeed_mask(ds):
    """

    :param ds:
    :return:
    """
    ind_below_2ms  = (ds['oswWindSpeed'].values<2)
    qualityvals = ds['swh_quality'].values
    swh_rejection_flags = ds['swh_rejection_flags'].values
    qualityvals[ind_below_2ms] = 2 #bad
    #swh_rejection_flags[ind_below_2ms] += np.int(2 ** 64)  # wind_below_2_m_per_sec
    aa = np.zeros(len(swh_rejection_flags)).astype(int)
    swh_rejection_flags[ind_below_2ms] += aa[ind_below_2ms] | (1 << 3)
    # je devrais faire comme ca pour les bytes flag_per += seaice_mask * np.int8(2 ** 2) (vu dans proc swiml2s)
    ds['swh_quality'] = xarray.DataArray(qualityvals,dims='time')
    ds['swh_rejection_flags'] = xarray.DataArray(swh_rejection_flags,dims='time')
    return ds

def apply_nv_mask(ds):
    """

    :param ds:
    :return:
    """
    max_nv_wv1 = 1.85 # a discuter avec Justin et Alexis valeur utilisee pour Maupiti project
    max_nv_wv2 = 1.3
    logging.info('Nv values: %s',ds['nv'].values)
    indwv1 = (ds['oswIncidenceAngle'].values<30)
    indwv2 = (ds['oswIncidenceAngle'].values>30)
    #if wv == 'wv1':
    ind_NVgreater1 = (ds['nv'].values > max_nv_wv1) & indwv1
    #else:
    ind_NVgreater2 = (ds['nv'].values > max_nv_wv2) & indwv2
    ind_NVgreater = ind_NVgreater1 | ind_NVgreater2
    qualityvals = ds['swh_quality'].values
    logging.info('%s observations with Nv flag raised ',ind_NVgreater.sum())
    swh_rejection_flags = ds['swh_rejection_flags'].values
    qualityvals[ind_NVgreater] = 2 #bad
    #swh_rejection_flags[ind_NVgreater] = 1  # nv_greater_than_max_nv
    #swh_rejection_flags[ind_NVgreater] += np.int(2 ** 1)
    aa = np.zeros(len(swh_rejection_flags)).astype(int)
    swh_rejection_flags[ind_NVgreater] += aa[ind_NVgreater] | (1 << 0)
    ds['swh_quality'] = xarray.DataArray(qualityvals,dims='time')
    ds['swh_rejection_flags'] = xarray.DataArray(swh_rejection_flags,dims='time')
    return ds

def apply_outlier_swh_based_on_uncertainty(ds):
    """

    :param ds:
    :return:
    """
    one_std = np.mean(ds['swh_uncertainty'].values) #it is a mean because swh_uncertainty is already an STD
    ind_outlier = (ds['swh_uncertainty'].values >= 2*one_std)
    qualityvals = ds['swh_quality'].values
    swh_rejection_flags = ds['swh_rejection_flags'].values
    logging.info('uncertainty : %s',ds['swh_uncertainty'].values)
    logging.info('limit outlier: %s',2*one_std)
    qualityvals[ind_outlier] = 1 #bad
    logging.info('%s observations with outlier flag raised ',ind_outlier.sum())
    #swh_rejection_flags[ind_outlier] += np.int(2 ** 2)  # swh_outlier
    aa = np.zeros(len(swh_rejection_flags)).astype(int)
    swh_rejection_flags[ind_outlier] += aa[ind_outlier] | (1 << 1)
    ds['swh_quality'] = xarray.DataArray(qualityvals,dims='time')
    ds['swh_rejection_flags'] = xarray.DataArray(swh_rejection_flags,dims='time')
    return ds


def apply_nan_mask(ds):
    """

    :param ds:
    :return:
    """
    ind_not_finite = (np.isfinite(ds['swh_uncertainty'].values)==False) | (np.isfinite(ds['swh'].values)==False)
    qualityvals = ds['swh_quality'].values
    swh_rejection_flags = ds['swh_rejection_flags'].values
    qualityvals[ind_not_finite] = 1 #bad
    logging.info('%s observations not finite ',ind_not_finite.sum())
    #swh_rejection_flags[ind_not_finite] += np.int(2 ** 4)  # swh_outlier
    aa = np.zeros(len(swh_rejection_flags)).astype(int)
    swh_rejection_flags[ind_not_finite] += aa[ind_not_finite] | (1 << 2)
    ds['swh_quality'] = xarray.DataArray(qualityvals,dims='time')
    ds['swh_rejection_flags'] = xarray.DataArray(swh_rejection_flags,dims='time')
    return ds

def write_netcdf_file_xarray ( s1_ocn_wv_ds,filout,cwave_version,redo=True ,remove_training_vars=True,safename=None) :
    """
    format output daily file (xarray replace cerbere)
    :args:
        s1_ocn_wv_ds : Xarray.Dataset
        wv (str): wv1 or wv2
        cwave_version (str):
        redo: (bool)
    """
    logging.debug('add swh_quality')
    qcs = 3*np.ones(len(s1_ocn_wv_ds['oswLon'])).astype(int) # default is good
    # one_std = np.std(s1_ocn_wv_ds['swh_uncertainty'].values)
    # qcs[s1_ocn_wv_ds['swh_uncertainty']<one_std] = 3
    # qcs[(s1_ocn_wv_ds['swh_uncertainty'] >= one_std) & (s1_ocn_wv_ds['swh_uncertainty'] < 2*one_std)] = 2
    # qcs[(s1_ocn_wv_ds['swh_uncertainty'] >= 2*one_std) ] = 1

    # defined default zeros quality flags
    s1_ocn_wv_ds['swh_quality'] = xarray.DataArray(qcs,dims=s1_ocn_wv_ds['swh_uncertainty'].dims,
                                                coords=s1_ocn_wv_ds['swh_uncertainty'].coords)
    #je met a zeros puis plus loin dans le code je met tout les indices encore a zeros comme masked
    flags_mean = np.zeros(len(s1_ocn_wv_ds['oswLon'])).astype('O')#*-32768 #pour pouvoir ajouter des bit 2**64 jai limpression que je suis oblige
    s1_ocn_wv_ds['swh_rejection_flags']= xarray.DataArray(flags_mean,
                                dims=s1_ocn_wv_ds['swh_uncertainty'].dims,coords=s1_ocn_wv_ds['swh_uncertainty'].coords)
    # apply quality flags
    s1_ocn_wv_ds = apply_outlier_swh_based_on_uncertainty(s1_ocn_wv_ds)
    s1_ocn_wv_ds = apply_nv_mask(s1_ocn_wv_ds)
    s1_ocn_wv_ds = apply_windspeed_mask(s1_ocn_wv_ds)
    s1_ocn_wv_ds = apply_landmask_in_rejection_flag(s1_ocn_wv_ds)
    s1_ocn_wv_ds = apply_nan_mask(s1_ocn_wv_ds)

    date_start = s1_ocn_wv_ds['time'].values[0].astype('datetime64[Y]').astype(int) + 1970
    ts = (s1_ocn_wv_ds['time'].values[0] - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')
    firstdate_dt = datetime.datetime.utcfromtimestamp(ts)
    logging.info('date_start : %s',date_start)
    s1_ocn_wv_ds = apply_sea_ice_mask(s1_ocn_wv_ds,firstdate_dt)
    s1_ocn_wv_ds['swh_rejection_flags'].values = s1_ocn_wv_ds['swh_rejection_flags'].values.astype(
        'u2')  # to have SHORT in netCDF
    s1_ocn_wv_ds['swh_rejection_flags'].values = np.ma.masked_where(s1_ocn_wv_ds['swh_rejection_flags'].values==0,
                                                                    s1_ocn_wv_ds['swh_rejection_flags'].values,copy=True)
    #add distance to coast
    landmask,distance_to_coast = swiml2sproc_utils_ancillary_landmask.get_landmask(s1_ocn_wv_ds['oswLon'].values,
                                    s1_ocn_wv_ds['oswLat'].values,land_polygon_path,land_raster_path,debug_figures=False)
    s1_ocn_wv_ds['distance_to_coast']= xarray.DataArray(distance_to_coast,
                                dims=s1_ocn_wv_ds['swh_uncertainty'].dims,coords=s1_ocn_wv_ds['swh_uncertainty'].coords)
    logging.debug('rename')
    s1_ocn_wv_ds  = s1_ocn_wv_ds.rename({'oswLon':'lon','oswLat':'lat','oswWindSpeed':'wind_speed'})
    if remove_training_vars:
        s1_ocn_wv_ds = s1_ocn_wv_ds.drop(['S','cwave','incidence','latlonSARcossin','dxdt','todSAR','oswIncidenceAngle'])
        s1_ocn_wv_ds = s1_ocn_wv_ds.drop(['oswQualityCrossSpectraRe','satellite','oswK','oswNrcs'])
        s1_ocn_wv_ds = s1_ocn_wv_ds.drop(['oswQualityCrossSpectraIm','Sdim','cwavedim','dxdtdim','latlondim','incdim',
                                          'oswAngularBinSize','oswWavenumberBinSize'])
    if len(s1_ocn_wv_ds['swh_uncertainty'])>0:

        #add var attributes
        for kk in s1_ocn_wv_ds.keys():
            logging.debug('att start with : %s',kk)
            if s1_ocn_wv_ds[kk].values.dtype=='float32' or s1_ocn_wv_ds[kk].values.dtype=='float64' or s1_ocn_wv_ds[kk].values.dtype=='int':
                # mask nan elements -> add a fillvalue
                masked_vals = np.ma.masked_where(np.isnan(s1_ocn_wv_ds[kk].values),s1_ocn_wv_ds[kk].values,copy=True)
            else:
                logging.info('variable %s doesnt contains numeric values : %s',kk,s1_ocn_wv_ds[kk].values.dtype)
                masked_vals = s1_ocn_wv_ds[kk].values
            if isinstance(masked_vals,np.ndarray):
                masked_vals = np.ma.array(masked_vals) #to have a valid fillvalue in netcdf attribut
                logging.debug('cast du masked : %s',type(masked_vals))
            s1_ocn_wv_ds[kk] = xarray.DataArray(masked_vals,dims=s1_ocn_wv_ds[kk].dims,coords=s1_ocn_wv_ds.coords)
            logging.debug('%s %s ',kk,type(s1_ocn_wv_ds[kk].values))
            if kk in variables_infos:

                s1_ocn_wv_ds[kk].attrs['unit'] = variables_infos[kk][3]
                s1_ocn_wv_ds[kk].attrs['longname'] =variables_infos[kk][4]
                s1_ocn_wv_ds[kk].attrs['standard_name'] = variables_infos[kk][0]
                if kk in ['platformName']:
                    pass
                else:
                    s1_ocn_wv_ds[kk].attrs['vmin'] =variables_infos[kk][5]
                    s1_ocn_wv_ds[kk].attrs['vmax'] =variables_infos[kk][6]
                s1_ocn_wv_ds[kk].attrs['coordinates'] = "lat lon"
                s1_ocn_wv_ds[kk].attrs['authority'] = "CF 1.7"
                s1_ocn_wv_ds[kk].attrs['least_significant_digit'] = '3L'
                #if 'fill_value' in dir(s1_ocn_wv_ds[kk].values): #je ne comprend pas pourquoi le type des values nest pas updated
                #    s1_ocn_wv_ds[kk].attrs['_FillValue'] = s1_ocn_wv_ds[kk].values.fill_value
                if kk in ['swh']:
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "physicalMeasurement"
                    s1_ocn_wv_ds[kk].attrs['ancillary_variables'] = "swh_quality swh_rejection_flags swh_uncertainty"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"
                elif kk in ['wind_speed']:
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "physicalMeasurement"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"
                elif kk in 'swh_quality':
                    s1_ocn_wv_ds[kk].attrs['least_significant_digit'] = '0L'
                    s1_ocn_wv_ds[kk].attrs['flag_values'] = "0L, 1L, 2L, 3L"
                    s1_ocn_wv_ds[kk].attrs['flag_meanings'] = "undefined bad acceptable good"
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "qualityInformation"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"
                elif kk in 'swh_rejection_flags':
                    s1_ocn_wv_ds[kk].attrs['least_significant_digit'] = '0L'
                    s1_ocn_wv_ds[kk].attrs['flag_masks'] = "1L, 2L, 4L, 8L, 16L, 32L, 64L, 128L"
                    #s1_ocn_wv_ds[kk].attrs['flag_meanings'] = "nb_of_valid_swh_too_low swh_validity not_water sea_ice sigma0_validity waveform_validity swh_rms_outlier swh_outlier"
                    s1_ocn_wv_ds[kk].attrs['flag_meanings'] = "nv_greater_than_max_nv swh_outlier invalid_value wind_below_2_m_per_sec not_water"
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "qualityInformation"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"
                    #s1_ocn_wv_ds[kk].attrs['_FillValue'] = -32768



                logging.debug('attrb for %s added: %s',kk,s1_ocn_wv_ds[kk].attrs)
            elif kk in ['time']:
                s1_ocn_wv_ds[kk].attrs['longname'] = "start time of the WV acquisition (lasts less than 3 seconds for one image)"
            else:
                logging.debug('no att for %s',kk)
        globatt = {
            'institution' : 'University of Hawaii , Laboratory of Physical and Spatial Oceanography  Institut FranÃ§ais pour la Recherche et l Exploitation de la MER, European Space Agency',
            'institution_abbreviation' : 'UH , LOPS-IFREMER, ESA',
            'publisher_name' : "ifremer/LOPS",
            'publisher_url' : "https://www.umr-lops.fr/",
            'publisher_email' : "lops-siam@listes.ifremer.fr",
            'PIs' : 'Justin Stopa, Alexis Mouche',
            #'reference paper' : 'Stopa, Mouche JGR oceans 2017 https://doi.org/10.1002/2016JC012364',
            'reference paper': 'Quach et al 2020 https://authors.library.caltech.edu/104562/1/09143500.pdf',
            #'incidence_angle' : wv,
            'version of NN model' : cwave_version,
            'time_coverage_start' : str(s1_ocn_wv_ds['time'].min().values), #"2017-01-01T00:28:08Z" ;             #new att like cerbere
            'time_coverage_end' : str(s1_ocn_wv_ds['time'].max().values),
            'Conventions' : "CF-1.7, ACDD-1.3, ISO 8601" ,
            'title' : "ESA CCI Sea State L2 ESA OCN from Sentinel-1",
            'id' : "ESACCI-SEASTATE-L2P-SWH-Sentinel1" ,
            #'institution = "Institut Francais de Recherche pour l\'Exploitation de la mer / CERSAT, European Space Agency" ;
            'source' : "CCI Sea State Sentinel-1 statistical Hs Processor",
            'history' : "%s - Creation"%datetime.datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'references' : "CCI Sea State Product Specification Document (PSD), v1.1",
            'product_version' : "1.0",
            'summary' : "This dataset contains significant wave height measurements from Sentinel-1 SAR" ,
            'keywords' : ("Oceans > Ocean Waves > Significant Wave Height", "Oceans > Ocean Waves > Sea State"),
            'keywords_vocabulary' : "NASA Global Change Master Directory (GCMD) Science Keywords",
            'naming_authority' : "fr.ifremer.cersat" ,
            'cdm_data_type' : "trajectory",
            'featureType' : "trajectory" ,
            'comment' : "These data were produced at ESACCI as part of the ESA SST CCI project.",
            'creator_name' : "ifremer/LOPS" ,
            'creator_url' : "https://www.umr-lops.fr/" ,
            'creator_email' : "lops-siam@listes.ifremer.fr" ,
            'creator_institution' : "Ifremer / LOPS" ,
            'project' : "Climate Change Initiative - European Space Agency" ,
            'geospatial_lat_min' : -80. ,
            'geospatial_lat_max' : 80. ,
            'geospatial_lat_units' : "degree_north" ,
            'geospatial_lon_min' : -180. ,
            'geospatial_lon_max' : 180. ,
            'geospatial_lon_units' : "degree_east" ,
            'standard_name_vocabulary' : "NetCDF Climate and Forecast (CF) Metadata Convention version 1.7" ,
            'license' : "ESA CCI Data Policy: free and open access" ,
            'platform' : "Sentinel-1" ,
            'platform_type' : "low earth orbit satellite" ,
            'platform_vocabulary' : "CCI" ,
            'instrument' : "C-band SAR" ,
            'instrument_type' : "SAR (Synthetic Aperture Radar)" ,
            'instrument_vocabulary' : "CCI" ,
            'spatial_resolution' : "20x20 km" ,
            'netcdf_version_id' : "%s"%netCDF4.__version__,
            'acknowledgement' : "Please acknowledge the use of these data with the following statement: these data were obtained from the ESA CCI Sea State project" ,
            'format_version' : "Data Standards v2.1" ,
            'processing_level' : "L2P" ,
            'scientific_support_contact' : "stopa@hawaii.edu" ,
            'technical_support_contact' : "cersat@ifremer.fr" ,
            'key_variables' : "swh" ,
            'date_created' : datetime.datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'date_modified' : datetime.datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'band' : "C" ,
            'source_version' : cwave_version ,
            'source_product': safename,
            'input' : "Level-2 ESA WV OCN products" ,
            'Metadata_Conventions' : "Climate and Forecast (CF) 1.7, Attribute Convention for Data Discovery (ACDD) 1.3" ,
            'geospatial_vertical_units' : "meters above mean sea level" ,
            'geospatial_vertical_positive' : "up"

        }
        for kki in globatt:
            s1_ocn_wv_ds.attrs[kki] = globatt[kki]
        float_fillvalue = netCDF4.default_fillvals['f8']

        encoding = {'lat' : {'zlib' : False,'_FillValue' : False},
                    'lon' : {'zlib' : False,'_FillValue' : False},
                    'swh_rejection_flags' : {'_FillValue' : -32768,'dtype':'u2'},
                    'incidence_angle' : {'_FillValue' : float_fillvalue},
                    'wind_speed' : {'_FillValue' : float_fillvalue},
                    'nrcs' : {'_FillValue' : float_fillvalue},
                    'nv' : {'_FillValue' : float_fillvalue},
                    'heading' : {'_FillValue' : float_fillvalue},
                    'swh' : {'_FillValue' : float_fillvalue},
                    'swh_uncertainty' : {'_FillValue' : float_fillvalue},
                    'swh_quality' : {'_FillValue' : 0},
                    'distance_to_coast' : {'_FillValue' : float_fillvalue},
                    }
        s1_ocn_wv_ds.to_netcdf(filout,encoding=encoding)
        logging.info('done! output : %s',filout)
        status = 'written'
    else :
        logging.info('there is no hs total SAR for this day and this satellite %s',filout)
        status = 'nodata'
    return status


def process_one_orbit_v2 ( safename,args ) :
    """
    wrapper of the different methods
    version 2: skip txt files and compute the Hs total directly from netCDF ESA OCN
    args:
        safename : str (basename L2 S1 WV)
    """
    logging.info('treat safe: %s',safename)
    final_df = None
    sat = safename[0 :3]
    if args.outputdir is None :
        #outputdir = os.path.join(OUTDIR,args.cwave_version,sat + '_' + args.wv)
        outputdir = os.path.join(OUTDIR,args.cwave_version,sat)
    else :
        #outputdir = os.path.join(args.outputdir,args.cwave_version,sat + '_' + args.wv)
        outputdir = os.path.join(args.outputdir,args.cwave_version,sat)
    datestart_from_safe = datetime.datetime.strptime(os.path.basename(safename).split('_')[5],'%Y%m%dT%H%M%S')
    # filout = os.path.join(outputdir,datestart_from_safe.strftime('%Y'),datestart_from_safe.strftime('%j'),
    #                       safename.replace('.SAFE','')+ '_level2_LOPS_SWH_SAR_%s.nc' % args.cwave_version)
    # version DLR
    filout = os.path.join(outputdir,datestart_from_safe.strftime('%Y'),datestart_from_safe.strftime('%j'),
                          'ESACCI-SEASTATE-L2P-SWH-Sentinel-%s-%s-QUACH2020-d%s-fv%s.nc'%(sat[1:],
                                        os.path.basename(safename).split('_')[5], args.cwave_version,FILE_VERSION))
    logging.info('final path: %s',filout)
    dira = os.path.dirname(filout)

    if os.path.exists(dira) is False :
        os.makedirs(dira,0o0755)
        logging.info('make dir %s',dira)
    if os.path.exists(filout) and args.redo == True :
        os.remove(filout)
    if os.path.exists(filout) and args.redo == False :
        status = 'already_in'
    else :
        logging.info('outputdir = %s',outputdir)
        final_ds = read_infos_from_WV_ifremer_archive_v3(safename,sat,dev=args.dev)
        if final_ds is not None:
            logging.debug('%s',final_ds.keys())
            logging.debug('%s',final_ds.count())
            logging.info('write the final netCDF')
            status = write_netcdf_file_xarray(final_ds,filout,cwave_version=args.cwave_version,redo=args.redo,safename=os.path.basename(safename))
        else:
            logging.info('No WV OCN data for safe : %s ',safename)
            status = 'nodata'
    return status,final_df


if __name__ == '__main__' :
    tinit = time.time()
    root = logging.getLogger()
    if root.handlers :
        for handler in root.handlers :
            root.removeHandler(handler)
    import argparse

    parser = argparse.ArgumentParser(description='hs_sar_product')
    parser.add_argument('--verbose',action='store_true',default=False)
    parser.add_argument('--outputdir',default=None,help='folder where the data will be written [optional]',
                        required=False)
    parser.add_argument('--safename',required=True,help=' .SAFE to process',type=str)
    #parser.add_argument('--wv',required=True,help='wv1 or wv2...',type=str)
    parser.add_argument('--redo',action='store_true',default=False,help='redo existing files nc')
    parser.add_argument('--cwave-version',required=True,help='example  v1.2')
    parser.add_argument('--dev',action='store_true',default=False,help='dev/test mode only 2 wv measu treated in a day')
    args = parser.parse_args()
    fmt = '%(asctime)s %(levelname)s %(filename)s(%(lineno)d) %(message)s'
    if args.verbose :
        logging.basicConfig(level=logging.DEBUG,format=fmt,
                            datefmt='%d/%m/%Y %H:%M:%S')
    else :
        logging.basicConfig(level=logging.INFO,format=fmt,
                            datefmt='%d/%m/%Y %H:%M:%S')
    #     datedt = datetime.datetime(2017,1,25,)
    model = load_quach2020_model_v2() #heteroskedastik 2017 for format validation before final model release from Hawaii team
    cptu = collections.defaultdict(int)

    t0 = time.time()
    if args.safename[-1] == '/':
        inputsafepath = args.safename[0:-1]
    else:
        inputsafepath = args.safename
    status,final_df = process_one_orbit_v2(os.path.basename(inputsafepath),args)
    cptu[status] += 1
    elapsed = datetime.timedelta(seconds=(time.time() - t0))
    logging.info('time to write one file = %s',elapsed)
    logging.info('counter = %s',cptu)
    logging.info('script main finished in %1.1f seconds',time.time()-tinit)
